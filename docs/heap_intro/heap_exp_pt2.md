---
title: Getting Dirty with the Details
layout: default
nav_order: 3
parent: Heap Introduction
---
## How the Heap Works Part 1: Allocation

As discussed previously, the heap is necessarily complex as a result of the flexibility it affords. It is the goal of this section to familiarise you with this complexity. The upfront cost of learning how the heap works will pay its dividends, as the heap is ripe with potential avenues for exploitation.

The first part will introduce you to the fundamental ideas in allocation. The second part will introduce deallocation.

### Memory Allocation

The heap begins its life as one large contiguous piece of memory.

```
low address                                         high address
+--------------------------------------------------------------+
|                                                              |
|                                                              |
+--------------------------------------------------------------+
```

When the program requests memory using the `malloc()` function, this contiguous segment is partitioned in two. The first part is a section of memory containing a number of bytes slightly larger than the number of bytes specified by the `malloc()` argument. We call this section of memory a **heap chunk**, or simply a chunk if the context is unambiguous. This memory has now been allocated by the heap to the program - the pointer returned by `malloc()` points to this chunk. The second part of the partition contains unallocated memory. As it turns out this region of memory is also a chunk, although it has a special name: the **top chunk**.

```
low address                                         high address
+--------------------------------------------------------------+
| Allocated | Top                                              |
| Chunk     | Chunk                                            |
+--------------------------------------------------------------+
```

The process is very similar for further allocations - the top chunk gives away enough memory to satisfy the request (always from the bottom) thereby reducing its own size in the process.

```
low address                                         high address
+--------------------------------------------------------------+
| Allocated | Allocated | Allocated | Top                      |
| Chunk     | Chunk     | Chunk     | Chunk                    |
+--------------------------------------------------------------+
```

### Chunks

Let's take a look at chunks in more detail, as they are the key constituents of the heap. We stated before that a chunk contains a number of bytes slightly larger than the amount requested. This is for a few reasons:
- The minimum size for a chunk is 32 bytes, or 0x20 in hexadecimal. This is because chunks need to store certain information once they have been deallocated, and 0x20 is the minimum amount of space required to store this data.
- The size of a chunk must be a multiple of 16 bytes, to ensure that the all of the chunks are 16 byte aligned. This alignment results in significant performance optimisations for allocations of large data structures. This means that the size expressed in hexadecimal will always end in a 0.
- Chunks have a certain amount of space reserved for metadata. This is known as the **chunk header** or header, and is positioned just before the actual contents of the chunk. The size of this field is 8 bytes on x64 architectures. The chunk header contains 4 pieces of information:
	- A `PREV_INUSE` flag indicating if the previous chunk is currently allocated.
	- An `IS_MMAPED` flag indicating if the chunk was large enough to be allocated off heap. We will not be discussing this aspect of the heap, as it only pertains to really large chunks (assume it is not set).
	- A `NON_MAIN_ARENA` flag indicating if the chunk is in the main arena or not. The concept of arenas comes up when dealing with multithreaded programs, and will not be discussed here (assume it is not set).
	- The size of the chunk.
	Since the chunk size is a multiple of 16 bytes, the lowest four bits will always be zero. This means that the lowest three of these bits can be used for the other three flags. The chunk size can then effectively use all 8 bytes to represent the size.

Let us take a look at some chunk allocation examples. Consider the following program:

``` C
#include <stdlib.h>

int main() {
	char *ptr1 = (char *) malloc((size_t) 40);
	char *ptr2 = (char *) malloc((size_t) 35);
	char *ptr3 = (char *) malloc((size_t) 8);
	free(ptr1);
	free(ptr2);
	free(ptr3);
	return 0;
}
```

First call to malloc asks for 40 bytes of memory. Since 8 bytes are required for the chunk header, the minimum size of the chunk is 48 bytes. Since 48 = 3 * 16, this will in fact be the chunk size. The `PREV_INUSE` bit will be set in this case, as there is no previous chunk (the memory is most definitely being used). Assuming the heap starts at address `0x100008`, and the top chunk initially contains `0x999990` bytes, we have the following layout for our heap currently:

```
         |      .....      |
         +-----------------+
0x100038 | 0x999961        | Top chunk
         +-----------------+
         |                 |
         |                 |
         |                 |
         |                 |
         |                 |
         +-----------------+
0x100008 | 0x31            | First chunk allocated
         +-----------------+
```

There are a couple of things to make note of here:
- Each value in the chunk header field ends in a 1. This indicates that the `PREV_INUSE` flag/bit is enabled.
- The remaining part of the value in the chunk header corresponds to the chunk size. The allocated chunk has size 0x30 which equals 48 in decimal. The top chunk has size 0x999960, which is 0x30 less than its starting size, since this is the amount of memory given away for the allocation.
- The choice of `0x100008` for the starting address was not completely arbitrary - a value of 8 for the least significant digit ensures that the actual contents of the chunk fall on an address that is a multiple of 16. This is what is mean by 16 byte alignment.

Now lets look at the second allocation, which asks for 35 bytes of memory. Again, factoring in the chunk header size the minimum size for this chunk is 43. Since the size needs to be a multiple of 16, we round up to the nearest multiple which is 48. The `PREV_INUSE` bit will be set as the first chunk is still allocated.

```
         |      .....      |
         +-----------------+
0x100068 | 0x999931        | Top chunk
         +-----------------+
         |                 |
         |                 |
         |                 |
         |                 |
         |                 |
         +-----------------+
0x100038 | 0x31            | Second chunk allocated
         +-----------------+
         |                 |
         |                 |
         |                 |
         |                 |
         |                 |
         +-----------------+
0x100008 | 0x31            | First chunk allocated
         +-----------------+
```

The last allocation requires 8 bytes for data, so including the header 16 bytes are required in total. This is a multiple of 16, however it is smaller than the minimum chunk size which is 32 bytes, meaning that the minimum chunk size is allocated. The `PREV_INUSE` flag is set as the second chunk is still allocated at this stage.

```
         |      .....      |
         +-----------------+
0x100088 | 0x999911        | Top chunk
         +-----------------+
         |                 |
         |                 |
         |                 |
         +-----------------+
0x100068 | 0x21            | Third chunk allocated
         +-----------------+
         |                 |
         |                 |
         |                 |
         |                 |
         |                 |
         +-----------------+
0x100038 | 0x31            | Second chunk allocated
         +-----------------+
         |                 |
         |                 |
         |                 |
         |                 |
         |                 |
         +-----------------+
0x100008 | 0x31            | First chunk allocated
         +-----------------+
```

There are a few remaining discussion points for allocation:
- The OS determines the initial size for the heap. If the top chunk becomes to small to service a malloc request, it can request for more memory from the OS. If the OS cannot provide any more memory, to the heap then the request fails (this is why it is important to always check the return value of malloc). In the next section we will look at how chunks are recycled once they are deallocated which assists malloc in servicing requests.
- Some sources will say that the chunk header size is 16 bytes. This is because the last 8 bytes of freed chunks are repurposed to store metadata for the next chunk. Since chunks are not always in a freed state I have not included this section in my definition of a header.

### Chunk Deallocation 

The lifetime of a chunk need not be the same as the programs duration. In fact, programmers should free chunks as soon as possible so that they can be used to service later malloc requests and prevent the heap from becoming full. However, since chunks are not all the same size and freed chunks do not have to be contiguous in memory, managing the freed chunks is a non-trivial exercise. As a simple example consider the following scenario, where a request for 24 bytes (so a total chunk size of 0x20) is made with the following heap state:

```
+------------+-----------------+------------+-----------------+
| 0x50       | 0x30            | 0x20       |                 |
+------------+-----------------+------------+-----------------+
| Free chunk | Allocated Chunk | Free Chunk | Top Chunk       |
+------------+-----------------+------------+-----------------+
```

Up until this point we have only seen allocations from the top chunk, and this would be the fastest option for our proposed allocation (provided we maintained a pointer to the top chunk). However it would not be the most efficient use of space as there are two chunks not being used that are large enough to service the request. Further, while the first chunk is large enough for the request, the third chunk is preferable as it is the exact size that we need. However we cannot simply search for a chunk of the perfect size, as for a large number of free chunks this search will take too long. We need a data structure to manage these chunks that provides the right blend of performance and memory efficiency in servicing malloc requests - this is the heart of the heaps complexity.

The solution provided by glibc is a hierarchy of linked lists called **bins**. We will first look at why the choice of linked lists makes sense in the first place, and then discuss the different types of bins used to optimise heap performance.

### Linked Lists in the Heap

When a chunk is freed, the data it contains is no longer important. Instead of wasting this space, we can use it to link together free chunks. Practically this is done using a doubly linked list - each free chunk contains a pointer to the next and previous free chunks in the list:

```
+-------------+
| Size        |
+-------------+
| FWD_POINTER |
| BCK_POINTER |
|             |
+-------------+
```

This means that instead of traversing the entire heap looking for free chunks, we can traverse the chunks directly looking for one of the correct size.

Whilst an improvement, this process is still slow - how long will it take to find a chunk of a given size? The solution here is to maintain multiple linked lists, each only storing chunks with the same (or similar) size. As indicated before, these linked lists are called bins.

### Bins in glibc

glibc maintains the following hierarchy of bins, which will each be introduced and discussed.

NOTE: Pay particular attention to the tcache bin, as it is the exploit target of the two CTF write ups included in this tutorial so far.

- tcache bins
- Fast bins
- Unsorted bin
- Small bins
- Large bins

The unsorted, small and large bins all exist in the same array, which stores pointers to the appropriate starting chunk for the bin.

```
+-----+----------+
| idx | Bin type |
+-----+----------+
| 0   | Unused   |
+-----+----------+
| 1   | Unsorted |
+-----+----------+
| 2   | Small    |
+-----+----------+
| ... |          |
+-----+----------+
| 63  | Small    |
+-----+----------+
| 64  | Large    |
+-----+----------+
| ... |          |
+-----+----------+
| 127 | Large    |
+-----+----------+
```

The fast bins and tcache bins are stored in their own arrays.
### Small Bins

We start with the small bins as they are the simplest to understand and the other bins are really variations on it to improve performance. There are 62 small bins, each storing chunks of a specific size. This means that on 64 bit systems, any chunk up to size 1024 can be stored in a small bin. Since each bin stores chunks of the same size it is automatically sorted, making insertion and deletion constant time operations (fast).

### Large Bins

Of course chunks can get larger than 1024 bytes - this is what the 63 large bins are for. Unlike small bins, large bins store chunks over a range of sizes. The ranges are small for smaller chunk sizes and increase as the chunk sizes increase. Further, the ranges are non-overlapping, meaning a chunk goes into exactly one small or large bin.

Since the large bins store chunks of different sizes, insertion and deletion are slower than in the fast bins. Certain optimisations exist to speed up this process - additional pointers in the chunk data section point to the next chunk of a larger/smaller size.

### Unsorted Bin

Consider the following observations about memory deallocations:
- Typically frees occur consecutively
- A free of a given chunk size is often followed by an allocation of the same size

These observations are capitalised on in the glibs heap implementation through the use of a single unsorted bin. As the name suggests, this bin stores chunks of any size in any order. 

Before being added to the unsorted bin chunks are **coalesced** - if the chunk being freed neighbours a free chunk in either direction, the chunks will be merged to create one large chunk (this is what the `PREV_INUSE` bit is used for). This coalescing reduces fragmentation, a situation where many active chunks are separated by small free chunks. It also makes the heap easier to manage, as one large is easier to track than multiple small ones. Note that chunks can be coalesced into the top chunk, however the resulting chunk is not added to the unsorted bin.

During memory allocation, the unsorted bin is traversed first. If a chunk is found that is of the right size for the request it is used. Otherwise, the chunk is allocated to the appropriate small or fast bin. This makes use of our second observation - recently deallocated chunks will be at the start of the unsorted bin and ready for an allocation of the same size.

### Fast Bins

The fast bins are used to store small chunks, allowing small memory requests to be serviced quickly. There are 7 fast bins, each corresponding to a specific chunk size between 32 and 128 bytes. If a chunk has a small enough size the correct fast bin will be used over the unsorted bin, meaning the chunk will not be coalesced. Not consolidating the chunks leads to fragmentation over time, so the heap periodically merges the chunks in the fast bins and places the resulting chunks in the unsorted bin. This usually occurs when a request is made that the fast bins cannot service.

### Tcache Bins

The tcache bins serve a role similar to the fast bins, and as such they are quite similar in structure. There are 64 tcache bins each storing chunks of a size between 32 and 1040 bytes. Unlike the fast bins, the tcache imposes a per bin limit of seven chunks.

The tcache bins solve a problem created by multithreaded programs. Multiple threads must coordinate accesses to shared resources to prevent bugs known as race conditions. The most common way to do this is with the use of locks. When a thread wants access to a shared resource it activates a lock, blocking other threads from accessing the resource. The blocked threads can only access the resource once the thread holding the lock relinquishes it. This method of protecting resources comes with two performance downsides:
- The blocked threads cannot perform meaningful work while they are waiting to acquire the lock.
- The lock itself causes an overhead that can be quite large if the lock is acquired frequently.

To solve these issues, the heap uses arenas (which are not discussed) and tcache bins. The tcache bins are allocated on a **per thread** basis i.e. each thread has its own set of 64 tcache bins. Before trying to acquire the lock and access the fast or unsorted bins, a thread can try and service a malloc request by checking its tcache bins which are not shared by other threads.

For our purposes this won't matter too much as we will be exploiting single threaded programs. The salient point is that freed chunks try to join a tcache bin before any of the others.






