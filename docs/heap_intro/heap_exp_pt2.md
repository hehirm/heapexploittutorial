---
title: "Heap Mechanics Part 2: Deallocation"
layout: default
nav_order: 3
parent: Heap Introduction
---
# Heap Mechanics Part 2: Deallocation

### Chunk Deallocation 

The lifetime of a chunk need not be the same as the programs duration. In fact, programmers should free chunks as soon as possible so that they can be used to service later malloc requests and prevent the heap from becoming full. However, since chunks are not all the same size and freed chunks do not have to be contiguous in memory, managing the freed chunks is a non-trivial exercise. As a simple example consider the following scenario, where a request for 24 bytes (so a total chunk size of 0x20) is made with the following heap state:

```
+------------+-----------------+------------+-----------------+
| 0x50       | 0x30            | 0x20       |                 |
+------------+-----------------+------------+-----------------+
| Free chunk | Allocated Chunk | Free Chunk | Top Chunk       |
+------------+-----------------+------------+-----------------+
```

Up until this point we have only seen allocations from the top chunk, and this would be the fastest option for our proposed allocation (provided we maintained a pointer to the top chunk). However it would not be the most efficient use of space as there are two chunks not being used that are large enough to service the request. Further, while the first chunk is large enough for the request, the third chunk is preferable as it is the exact size that we need. However we cannot simply search for a chunk of the perfect size, as for a large number of free chunks this search will take too long. We need a data structure to manage these chunks that provides the right blend of performance and memory efficiency in servicing malloc requests - this is the heart of the heaps complexity.

The solution provided by glibc is a hierarchy of linked lists called **bins**. We will first look at why the choice of linked lists makes sense in the first place, and then discuss the different types of bins used to optimise heap performance.

### Linked Lists in the Heap

When a chunk is freed, the data it contains is no longer important. Instead of wasting this space, we can use it to link together free chunks. Practically this is done using a doubly linked list - each free chunk contains a pointer to the next and previous free chunks in the list:

```
+-------------+
| Size        |
+-------------+
| FWD_POINTER |
| BCK_POINTER |
|             |
+-------------+
```

This means that instead of traversing the entire heap looking for free chunks, we can traverse the chunks directly looking for one of the correct size.

Whilst an improvement, this process is still slow - how long will it take to find a chunk of a given size? The solution here is to maintain multiple linked lists, each only storing chunks with the same (or similar) size. As indicated before, these linked lists are called bins.

### Bins in glibc

glibc maintains the following hierarchy of bins, which will each be introduced and discussed.

NOTE: Pay particular attention to the tcache bin, as it is the exploit target of the two CTF write ups included in this tutorial so far.

- tcache bins
- Fast bins
- Unsorted bin
- Small bins
- Large bins

The unsorted, small and large bins all exist in the same array, which stores pointers to the appropriate starting chunk for the bin.

```
+-----+----------+
| idx | Bin type |
+-----+----------+
| 0   | Unused   |
+-----+----------+
| 1   | Unsorted |
+-----+----------+
| 2   | Small    |
+-----+----------+
| ... |          |
+-----+----------+
| 63  | Small    |
+-----+----------+
| 64  | Large    |
+-----+----------+
| ... |          |
+-----+----------+
| 127 | Large    |
+-----+----------+
```

The fast bins and tcache bins are stored in their own arrays.
### Small Bins

We start with the small bins as they are the simplest to understand and the other bins are really variations on it to improve performance. There are 62 small bins, each storing chunks of a specific size. This means that on 64 bit systems, any chunk up to size 1024 can be stored in a small bin. Since each bin stores chunks of the same size it is automatically sorted, making insertion and deletion constant time operations (fast).

### Large Bins

Of course chunks can get larger than 1024 bytes - this is what the 63 large bins are for. Unlike small bins, large bins store chunks over a range of sizes. The ranges are small for smaller chunk sizes and increase as the chunk sizes increase. Further, the ranges are non-overlapping, meaning a chunk goes into exactly one small or large bin.

Since the large bins store chunks of different sizes, insertion and deletion are slower than in the fast bins. Certain optimisations exist to speed up this process - additional pointers in the chunk data section point to the next chunk of a larger/smaller size.

### Unsorted Bin

Consider the following observations about memory deallocations:
- Typically frees occur consecutively
- A free of a given chunk size is often followed by an allocation of the same size

These observations are capitalised on in the glibs heap implementation through the use of a single unsorted bin. As the name suggests, this bin stores chunks of any size in any order. 

Before being added to the unsorted bin chunks are **coalesced** - if the chunk being freed neighbours a free chunk in either direction, the chunks will be merged to create one large chunk (this is what the `PREV_INUSE` bit is used for). This coalescing reduces fragmentation, a situation where many active chunks are separated by small free chunks. It also makes the heap easier to manage, as one large is easier to track than multiple small ones. Note that chunks can be coalesced into the top chunk, however the resulting chunk is not added to the unsorted bin.

During memory allocation, the unsorted bin is traversed first. If a chunk is found that is of the right size for the request it is used. Otherwise, the chunk is allocated to the appropriate small or fast bin. This makes use of our second observation - recently deallocated chunks will be at the start of the unsorted bin and ready for an allocation of the same size.

### Fast Bins

The fast bins are used to store small chunks, allowing small memory requests to be serviced quickly. There are 7 fast bins, each corresponding to a specific chunk size between 32 and 128 bytes. If a chunk has a small enough size the correct fast bin will be used over the unsorted bin, meaning the chunk will not be coalesced. Not consolidating the chunks leads to fragmentation over time, so the heap periodically merges the chunks in the fast bins and places the resulting chunks in the unsorted bin. This usually occurs when a request is made that the fast bins cannot service.

### Tcache Bins

The tcache bins serve a role similar to the fast bins, and as such they are quite similar in structure. There are 64 tcache bins each storing chunks of a size between 32 and 1040 bytes. Unlike the fast bins, the tcache imposes a per bin limit of seven chunks.

The tcache bins solve a problem created by multithreaded programs. Multiple threads must coordinate accesses to shared resources to prevent bugs known as race conditions. The most common way to do this is with the use of locks. When a thread wants access to a shared resource it activates a lock, blocking other threads from accessing the resource. The blocked threads can only access the resource once the thread holding the lock relinquishes it. This method of protecting resources comes with two performance downsides:
- The blocked threads cannot perform meaningful work while they are waiting to acquire the lock.
- The lock itself causes an overhead that can be quite large if the lock is acquired frequently.

To solve these issues, the heap uses arenas (which are not discussed) and tcache bins. The tcache bins are allocated on a **per thread** basis i.e. each thread has its own set of 64 tcache bins. Before trying to acquire the lock and access the fast or unsorted bins, a thread can try and service a malloc request by checking its tcache bins which are not shared by other threads.

For our purposes this won't matter too much as we will be exploiting single threaded programs. The salient point is that freed chunks try to join a tcache bin before any of the others.






